\subsection{Предварительные сведения}
\label{sub:preliminary}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{Определения и обозначения}
\label{ssub:definitions}

Формально сложная сеть может быть представлена с помощью графа. В работе будут рассматриваться только невзвешенные неориентированные графы. Неориентированный невзвешенный граф $G = (\mathscr{N}, \mathscr{L})$ состоит из двух множеств --- множества $\mathscr{N} \ne \emptyset$, элементы которого называются \emph{узлами} или \emph{вершинами} графа, и множества $\mathscr{L}$ неупорядоченных пар из множества $\mathscr{N}$, элементы которого называются \emph{ребрами} или \emph{связями}. Мощности множеств $\mathscr{N}$ и $\mathscr{L}$ равны $N$ и $L$ соответственно.

Узел обычно обозначают по его порядковому месту $i$ в множестве $\mathscr{N}$, а ребро, соединяющее пару узлов $i$ и $j$ обозначают $l_{ij}$. Узлы, между которыми есть ребро называются \emph{смежными}. Степенью узла назовают величину $s_i$, равную количеству ребер, выходящих узла $i$.

Пусть $G = (\mathscr{N}, \mathscr{L})$ --- граф, \emph{разбиением на сообщества} будем называть разбиение множества его вершин $P = \{C_1, \dots, C_K\}$, то есть $\bigcup_{i = 1}^K C_i = \mathscr{N}$ и $C_i \cap C_j = \emptyset \ \forall i \neq j \in 1..K$.

Множество сообществ $P = \{C_1, \dots, C_{K_1}\}$ будем называеть разбиением на сообщества \emph{на основе} разбиения $\widetilde{P} = \left\{\widetilde{C}_1, \dots \widetilde{C}_{K_2}\right\}$, если $\forall i \in 1..K_2\ \exists  j \in 1..K_1: \widetilde{C}_i \subset C_j$.

Нефорально, сообщество --- это тесно сплоченное подмножество узлов графа $\mathscr{N}' \subset \mathscr{N}$. Два сообщества называются \emph{смежными}, если существует ребро, направленное из вершины первого сообщества в вершину второго.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{Модулярность}
\label{ssub:modularity}

В 2004 году в \cite{Newman&Girvan:2004} была введена целевая функция \emph{модулярность}, оценивающая неслучайность разбиения графа на сообщества.

Допустим, имеется $K$ сообществ, тогда \emph{нормированная матрица смежности сообществ} $\mathbf{e}$ определяется как симметричная матрица размером $K \times K$, где элементы $e_{ij}$ равны отношению количества ребер, которые идут из сообщества $i$ в сообщество $j$, к полному количеству ребер в графе (ребра $l_{mn}$ и $l_{nm}$ считаются различными, где $m$, $n$ --- узлы). След этой матрицы $\mathrm{Tr} (\mathbf{e}) = \sum_{i \in 1..K}{e_{ii}}$ показывает отношение ребер в сети, которые соединяют узлы одного и того же сообщества, к полному количеству ребер в графе. Хорошее разбиение на сообщества должно иметь высокое значение следа.

Однако если поместить все вершины в одно сообщество --- след примет максимальное возможное значение, притом, что такое разбиение не будет сообщать ничего полезного о графе. Поэтому определяется вектор $\mathbf{a}$ длины $K$ с элементами $a_i = \sum_{j \in 1..K}{e_{ij}}$. Координата вектора $a_i$ является \emph{нормированной степенью сообщества} $i$ и обозначает долю количества ребер, идущих к узлам, принадлежащим сообществу $i$, к полному количеству ребер в графе. Если в графе ребра проходят между вершинами независимо от сообществ --- $e_{ij}$ будет в среднем равно $a_i a_j$, поэтому модулярность можно определить следующим образом \cite{Newman&Girvan:2004}:
\begin{equation} \label{eq:modularity}
Q(G, P) = \sum_{i \in 1..K}{\left(e_{ii} - a_i^2\right)} = \mathrm{Tr} (\mathbf{e}) - \|\mathbf{e}^2\|,
\end{equation}
где $\|\mathbf{x}\|$ является суммой элементов матрицы $\mathbf{x}$. Если сообщества распределены не лучше, чем в случайном разбиении --- модулярность будет примерно равна 0. Максимальным возможным значением функции будет 1.

Теперь можно поставить задачу выделения сообществ следующим образом: \emph{требуется найти} такое разбиение графа, на котором модулярность принимает максимальное значение. Можно заметить, что такая постановка задачи не использует какого-либо определения сообществ.

Такая задача все еще будет NP-сложной \cite{Brandes&al:2008}. Однако преимущество модулярности состоит в том, что для того, чтобы посчитать, какой выигрыш будет извлечен из объединения двух сообществ, необходимо произвести только одну операцию: $\Delta Q = 2(e_{ij} - a_i a_j),$ где $i$ и $j$ --- потенциально объединяемые сообщества. Для того, чтобы объединить два сообщества необходимо сделать $O(\min\{n_i, n_j\})$ операций, где $n_i$ и $n_j$ обозначают количество смежных к $i$ и $j$ сообществ.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{Рандомизированный жадный алгоритм (RG)}
\label{ssub:rg}

Эффективными оказались рандомизированные алгоритмы максимизации модулярности. В 2010 году Овельгенне и Гейер-Шульц в \cite{Ovelgoenne&Geyer-Schulz:2010} был предложен рандомизированный жадный алгоритм (Randomized Greedy, \emph{RG}), который на каждой итерации рассматривает $k$ случайных сообществ и смежным к ним сообществ, а затем соединяет пару соседей, дающую наибольший выигрыш.

При отсутствии базового разбиения, на основе которого выделяются сообщества --- перед первой итерацией граф разбивается на $K = N$ сообществ с одним узлом в каждом сообществом. Алгоритм останавливается в тот момент, когда не остается больше сообществ для объединения, однако применяются объединения сообществ до той итерации, когда объединение последний раз принесло глобальный выигрыш.

Далее в работе рандомизированный жадный алгоритм с параметром $k$ будет обозначаться $RG_k$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{Схема кластеризации основных групп графа (CGGC)}
\label{ssub:cggc}

В 2012 году Овельгенне и Гейер-Шульц выиграли конкурс 10th DIMACS Implementation Challenge в категории \emph{кластеризация графа} со схемой кластеризации основных групп графа (Core Groups Graph Cluster, \emph{CGGC})  \cite{Ovelgoenne&Geyer-Schulz:2012b}. Схема заключается в том, что сначала $s$ \emph{начальных алгоритмов} разбивают граф на сообщества. В тех вершинах, относительно которых начальные алгоритмы разошлись во мнении, выделяет по сообществам \emph{финальный алгоритм}.

Формально это записывается следующим образом:
\begin{enumerate}
	\item $s$ начальных алгоритмов создают разбиения графа $G$ на сообщества. $S$ --- множество \emph{начальных разбиений}, то есть разбиений, полученных начальными алгоритмами
	\item Создается \emph{промежуточное разбиение} $\widetilde{P}$, равное максимальному перекрытию начальных разбиений из множества $S$
	\item Финальным алгоритмом создается разбиение $P$ графа $G$ на основе промежуточного разбиения $\widetilde{P}$
\end{enumerate}

Необходимо определить понятие \emph{максимальное перекрытие}. Пусть существует множество разбиений $S = \{P_1, \dots, P_s\}$, отображение $c_P(v)$ указывает, в каком сообществе находится узел $v$ в разбиении $P$.
Тогда у максимального перекрытия $\widetilde{P}$ множества $S$ будут следующие свойства:
$$v, w \in \mathscr{N}, \forall i \in 1..s :\ c_{P_i}(v) = c_{P_i}(w) \Rightarrow c_{\widetilde{P}}(v) = c_{\widetilde{P}}(w)$$
$$v, w \in \mathscr{N}, \exists i \in 1..s :\ c_{P_i}(v) \ne c_{P_i}(w) \Rightarrow c_{\widetilde{P}}(v) \ne c_{\widetilde{P}}(w)$$

Существует итеративная версия схемы кластеризации основных групп графа, в которой начальные алгоритмы вновь выделяют сообщества на основе промежуточного разбиения до тех пор, пока это будет увеличивать модулярность промежуточного разбиения. Такой алгоритм далее обозначается как \emph{CGGCi}. В качестве начальных и финального алгоритма можно использовать $RG_k$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{Одновременно возмущаемая стохастическая\\ аппроксимация (SPSA)}
\label{ssub:spsa}

Стохастическая аппроксимация была введена Роббинсом и Монро в 1951 году \cite{Robbins&Monro:1951} и затем была использована для решения оптимизационный задач Кифером и Вольфовицем \cite{Kiefer&Wolfowitz:1952}. В \cite{Blum:1954} алгоритм стохастической аппроксимации был расширен до многомерного случая. В $m$-мерном пространстве обычная KW-процедура, основанная на конечно-разностной аппроксимации градиента, использовала $2m$ измерений на каждой итерации (по два измерения на каждую координату градиента). Последовательно Граничин \cite{Granichin:1989}, Поляк и Цыбаков \cite{Polyak&Cybakov:1990} и Спалл \cite{Spall:1992} предложили алгоритм \emph{одновременно возмущаемой стохастической аппроксимации} (\emph{SPSA}), который на каждой итерации использует всего два измерения. Алгоритм \emph{SPSA} имеет такую же скорость сходимости, несмотря на то, что в многомерном случае (даже при $m \to \infty$) в нем используется заметно меньше измерений \cite{Spall:2005}.

Алгоритмы стохастической аппроксимации показали свою эффективность в решении задач минимизации стационарных функционалов. В \cite{Polyak:1987} для функционалов, меняющихся со временем были применены метод Ньютона и градиентный метод, но они применимы только в случае дважды дифференцируемых функционалов и в случае известных ограничений на Гессиан функционала. Так же оба метода требуют возможности вычисления градиента в произвольной точке.

Общую схему одновременно возмущаемой стохастической аппроксимации можно представить следующим образом:

\begin{enumerate}
	\item Выбор начального приближения $\hat{\theta}_0 \in \mathbb{R}^m$, счетчик $n \leftarrow 0$, выбор параметров алгоритма $d \in \mathbb{R} \setminus \{0\}$, $\{\alpha_n\} \subset \mathbb{R}^m$
	\item Увеличение счетчика $n \leftarrow n + 1$
	\item Выбор вектора возмущения $\Delta_n \in \mathbb{R}^m$, чьи координаты независимо генерируются по распределению Бернулли, дающему $\pm1$ с вероятностью $\frac{1}{2}$ для каждого значения
	\item Определение новых аргументов функционала $\theta_{n}^{-} \leftarrow \hat{\theta}_{n - 1} - d\Delta_{n}$ и $\theta_{n}^{+} \leftarrow \hat{\theta}_{n - 1} + d\Delta_{n}$
	\item Вычисление значений функционала $y_n^{-} \leftarrow f(\theta_{n}^{-}),\ y_n^{+} \leftarrow f(\theta_{n}^{+})$
	\item Вычисление следующей оценки
	\begin{equation} \label{eq:spsa-central}
		\hat{\theta}_n \leftarrow \hat{\theta}_{n - 1} - \alpha_n \Delta_{n} \frac{y_n^{+} - y_n^{-}}{2d}
	\end{equation}
	\item Далее происходит либо остановка алгоритма, либо переход на второй пункт
\end{enumerate}

В \cite{Kushner&Yin:2003, Borkar:2008, Granichin&Amelina:2015} рассматривается метод стохастической аппроксимации с постоянным размером шага, в таком случае вместо последовательности $\{\alpha_n\}$ используется единственный параметр $\alpha \in \mathbb{R}^m$, и следующая оценка вычисляется по следующей формуле вместо \eqref{eq:spsa-central}:
\begin{equation}
	\hat{\theta}_n \leftarrow \hat{\theta}_{n - 1} - \alpha \Delta \frac{y_n^{+} - y_n^{-}}{2d}
\end{equation}

Это позволяет эффективно решать проблемы очень плохого начального приближения $\hat{\theta}_0$ и дрейфующей оптимальной точки, когда аргумент, при котором функционал принимает лучшие значения, меняется со временем.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{Постановка задачи адаптации параметров алгоритма}
\label{ssub:problem_statement}

Рандомизированный жадный алгоритм имеет один параметр $k$, в то время как на результаты схемы кластеризации основных групп графа влияют параметр $s$ и параметры начальных и финального алгоритма.

Часто алгоритмы на разных входных данных имеют разные оптимальные параметры, то есть нет одного набора параметров, решающих каждую задачу наилучшим образом. При одних и тех же параметрах некоторые графы будут разбивать хорошо, в то время как другие --- критически плохо. Алгоритм \emph{SPSA} показал хорошие результаты в создании адаптивных модификаций алгоритмов, то есть модификаций, подстраивающих параметры под входные данные.

В работе рассматривается применение алгоритма \emph{SPSA} к алгоритмам \emph{RG} и \emph{CGGC} для создания алгоритмов, хорошо выделяющих сообщества на большем количестве графов, чем при основных наборах параметров этих рандомизированных алгоритмов.

\subsubsection*{Оценка качества}
\label{ssub:quality}

Для оценки качества сообщества используется целевая функция модулярность \eqref{eq:modularity}, а в качестве тестовых данных --- графы, используемые для оценки алгоритмов на конкурсе 10th DIMACS Implementation Challenge, которые можно найти по адресу \url{http://www.cc.gatech.edu/dimacs10/archive/clustering.shtml}. Граф \emph{celegans\_ metabolic} в работе обозначается как \emph{celegans}.

Так же в качестве тестового графа использовался синтетический граф \emph{auto40} из $N = 40,000$ вершин, $K = 40$ сообществ, и с вероятностями $p_1 = 0.1$ и $p_2 = 10^{-4}$ обнаружить связь между вершинами одного сообщества или вершинами разных сообществ, соответственно.